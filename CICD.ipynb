{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f07a5b",
   "metadata": {},
   "source": [
    "# CI / CD with CML API V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2c717",
   "metadata": {},
   "source": [
    "##### Cloudera Machine Learning exposes a REST API that you can use to perform operations related to projects, jobs, and runs. You can use API commands to integrate CML with third-party workflow tools or to control CML from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcd355",
   "metadata": {},
   "source": [
    "##### This notebook demonstrates how to create and execute three CML jobs with the CML API V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a70956",
   "metadata": {},
   "source": [
    "For the Public Documentation please visit this [page](https://docs.cloudera.com/machine-learning/cloud/api/topics/ml-api-v2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b5b10",
   "metadata": {},
   "source": [
    "For a full example of the API's capabilities, please visit this notebook from [Cloudera's Public GitHub](https://github.com/cloudera/CML_AMP_APIv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcca62",
   "metadata": {},
   "source": [
    "#### To use the Python API in your own code, first install the Python API client and point it to your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784c14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install the API\n",
    "\n",
    "import os\n",
    "cluster = os.getenv(\"CDSW_DOMAIN\")\n",
    "\n",
    "# If you are not on a TLS enabled cluster (your cluster url starts with ‘http’),\n",
    "# please use the following command instead.\n",
    "# !pip3 install http://{cluster}/api/v2/python.tar.gz\n",
    "#!pip3 install https://{cluster}/api/v2/python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1362390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oeqjbk'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmlapi.utils import Cursor\n",
    "import cmlapi\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "\n",
    "try:\n",
    "    client = cmlapi.default_client()\n",
    "except ValueError:\n",
    "    print(\"Could not create a client. If this code is not being run in a CML session, please include the keyword arguments \\\"url\\\" and \\\"cml_api_key\\\".\")\n",
    "\n",
    "session_id = \"\".join([random.choice(string.ascii_lowercase) for _ in range(6)])\n",
    "session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4037c97",
   "metadata": {},
   "source": [
    "##### The API has a lot of cool features. For example, it allows you to view all runtimes associated with the CML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "311e842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor also supports search_filter\n",
    "# cursor = Cursor(client.list_runtimes, \n",
    "#                 search_filter = json.dumps({\"image_identifier\":\"jupyter\"}))\n",
    "cursor = Cursor(client.list_runtimes)\n",
    "runtimes = cursor.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "761df8e9-f24b-4700-ab9e-34e1ba74f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'next_page_token': '',\n",
      " 'runtime_addons': [{'component': 'HadoopCLI',\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.10 - HOTFIX-1',\n",
      "                     'identifier': 'hadoop-cli-7.2.10-hf1',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.11 - HOTFIX-4',\n",
      "                     'identifier': 'hadoop-cli-7.2.11-hf4',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.14',\n",
      "                     'identifier': 'hadoop-cli-7.2.14',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.8 - HOTFIX-1',\n",
      "                     'identifier': 'hadoop-cli-7.2.8-hf1',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'display_name': 'Spark 2.4.8 - CDE 1.15 - HOTFIX-1',\n",
      "                     'identifier': 'spark248-15-hf1',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'display_name': 'Spark 3.2.0 - CDE 1.15 - HOTFIX-2',\n",
      "                     'identifier': 'spark320-15-hf2',\n",
      "                     'status': 'AVAILABLE'}]}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import cmlapi\n",
    "from cmlapi.rest import ApiException\n",
    "from pprint import pprint\n",
    "\n",
    "try:\n",
    "    # List the available runtime addons, optionally filtered, sorted, and paginated.\n",
    "    api_response = client.list_runtime_addons(page_size=500)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling CMLServiceApi->list_runtime_addons: %s\\n\" % e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15403f5",
   "metadata": {},
   "source": [
    "##### Similarly, you can see all jobs in the current CML Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919557ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 0 jobs from the project\n"
     ]
    }
   ],
   "source": [
    "### GET ALL PREVIOUS JOBS FROM PROJECT ###\n",
    "    \n",
    "project_id = os.environ[\"CDSW_PROJECT_ID\"]\n",
    "\n",
    "joblists = client.list_jobs(project_id = project_id)\n",
    "print(f'Fetched {len(joblists.jobs)} jobs from the project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1b731c9-3830-411d-ab78-968577064ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7vvz-ir4l-nvfi-ehzk'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b883bc",
   "metadata": {},
   "source": [
    "## You can build ML Ops Pipelines by creating and executing CML Jobs with the API from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8c082",
   "metadata": {},
   "source": [
    "##### First we create a CML Job to train a model. We trained this model in ProtoType.py but in a real world scenario you may have created your model baseline with ML Flow, also available in CML under the Experiments tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1801a2f2-b0b7-448b-8029-ca930f90fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cml_runtime = \"docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-standard:2022.04.1-b6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcebb2f3-d1dc-4a75-9fe0-c59d9c1c6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO TEST THE DATA\n",
    "\n",
    "# Create a dependent job by specifying the parent job's ID in the parent_job_id field.\n",
    "preprocessing_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"1_preprocessing-job\",\n",
    "    script = \"cicd/1_preprocessing.py\",\n",
    "    kernel = \"python3\",\n",
    "    cpu = 2,\n",
    "    memory = 4,\n",
    "    runtime_identifier = cml_runtime\n",
    ")\n",
    "preprocessing_job = client.create_job(preprocessing_job_body, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "782cfbb7-5a31-472f-b964-56baacbff7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO TEST THE DATA\n",
    "\n",
    "# Create a dependent job by specifying the parent job's ID in the parent_job_id field.\n",
    "testing_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"2_unit-tests-job\",\n",
    "    script = \"cicd/2_testing.py\",\n",
    "    kernel = \"python3\",\n",
    "    cpu = 1,\n",
    "    memory = 2,\n",
    "    runtime_identifier = cml_runtime,\n",
    "    parent_job_id = preprocessing_job.id\n",
    ")\n",
    "testing_job = client.create_job(testing_job_body, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e548672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO RETRAIN THE MODEL ###\n",
    "    \n",
    "# Create a job. We will create dependent/children jobs of this job, so we call this one a \"grandparent job\". The parameter \"runtime_identifier\" is needed if this is running in a runtimes project.\n",
    "train_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"3_train-job\",\n",
    "    script = \"cicd/3_exp_train_rf.py\",\n",
    "    cpu = 4.0,\n",
    "    memory = 16.0,\n",
    "    runtime_identifier = cml_runtime,\n",
    "    parent_job_id = testing_job.id\n",
    ")\n",
    "# Create this job within the project specified by the project_id parameter.\n",
    "train_job = client.create_job(train_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ec40a",
   "metadata": {},
   "source": [
    "##### A second CML Job to push the model to a REST Endpoint can be set to execute as a dependency on the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0428839",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO PUSH THE MODEL TO A REST ENDPOINT ###\n",
    "\n",
    "# Create a dependent job by specifying the parent job's ID in the parent_job_id field.\n",
    "deploy_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"4_deploy-model-job\",\n",
    "    script = \"cicd/4_deploy.py\",\n",
    "    kernel = \"python3\",\n",
    "    cpu = 2,\n",
    "    memory = 4,\n",
    "    runtime_identifier = cml_runtime,\n",
    "    parent_job_id = train_job.id\n",
    ")\n",
    "#    runtime_addon_identifiers = [\"spark311-13-hf1\"],\n",
    "deploy_job = client.create_job(deploy_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89adb0-5eae-4f95-bddd-6ae40b6e8124",
   "metadata": {},
   "source": [
    "##### A third CML Job to push the model to a REST Endpoint can be set to execute as a dependency on the first one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07d9a53",
   "metadata": {},
   "source": [
    "##### Finally a third job can be created to perform Model Inference. This job is dependent on the second job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5608a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO DO INFERENCE ON THE MODEL ###\n",
    "\n",
    "# Create a job that is dependent on the job from the previous cell. This leads to a dependency chain of grandparent_job -> parent_job -> child_job. If grantparent_job runs and succeeds, then parent_job will trigger, and if parent_job runs and succeeds, child_job will trigger. This one uses a template script that does not terminate, so we'll have the opportunity to try stopping it later.\n",
    "inference_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"5_inference-job\",\n",
    "    script = \"cicd/5_inference.py\",\n",
    "    kernel = \"python3\",\n",
    "    cpu = 2,\n",
    "    memory = 4,\n",
    "    runtime_identifier = cml_runtime,\n",
    "    parent_job_id = deploy_job.id\n",
    ")\n",
    "inference = client.create_job(inference_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd075b",
   "metadata": {},
   "source": [
    "##### Next, we can use the API to run the first job. When it succeeds, the second job will execute, and then the third..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job run for the specified job.\n",
    "# If the job has dependent jobs, the dependent jobs will run after the job succeeds.\n",
    "# In this case, the grandparent job will run first, then the parent job, and then the child job, provided each job run succeeds.\n",
    "jobrun_body = cmlapi.CreateJobRunRequest(project_id, preprocessing_job.id)\n",
    "job_run = client.create_job_run(jobrun_body, project_id, preprocessing_job.id)\n",
    "run_id = job_run.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05ffed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
