{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6119b373-9290-4c9b-8fb7-8dfc88ca5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import TimeSÃ¹iesSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "#from prettytable import PrettyTable\n",
    "\"\"\"\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "38bb754c-2978-4bc7-8835-67b15360176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create version without iceberg extension options for CDE\n",
    "spark = SparkSession.builder\\\n",
    "  .appName(\"0.2 - Batch Load into Icerberg Table\") \\\n",
    "  .config(\"spark.hadoop.fs.s3a.s3guard.ddb.region\", \"us-west-2\")\\\n",
    "  .config(\"spark.kerberos.access.hadoopFileSystems\", \"s3a://ps-uat2\")\\\n",
    "  .config(\"spark.jars\",\"/home/cdsw/lib/iceberg-spark-runtime-3.2_2.12-0.13.2.jar\") \\\n",
    "  .config(\"spark.sql.extensions\",\"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog\",\"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog.type\",\"hive\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "485e1666-b290-47a1-97e3-b39948d121cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load data from Iceberg\n",
    "df_raw = spark.sql(\"SELECT * FROM spark_catalog.default.pump_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6388b761-4ec5-44d9-8410-a45dd6f65162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_raw_pandas =  df_raw.toPandas()\n",
    "#df_raw_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23bad4e8-5c49-4fd6-ab8f-f4300020d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL = 1 and RECOVERING & BROKEN = 0\n",
    "df = df_raw.withColumn('machine_status_tmp', when(df_raw.machine_status == \"NORMAL\", 1)\\\n",
    "                                    .when(df_raw.machine_status == \"RECOVERING\", 0)\\\n",
    "                                    .when(df_raw.machine_status == \"BROKEN\", 0)\\\n",
    "                                    .otherwise('Unknown'))\\\n",
    "                                    .drop(df_raw.machine_status)\\\n",
    "                                    .withColumnRenamed(\"machine_status_tmp\", \"machine_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66c71e57-a334-4c81-80d7-3f3059eb305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distributions of target class: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "|machine_status| count|\n",
      "+--------------+------+\n",
      "|             0| 21757|\n",
      "|             1|308214|\n",
      "+--------------+------+\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Distributions of target class: \")\n",
    "print(df.groupBy('machine_status').count().orderBy('count').show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2127fa06-9f58-45e6-a894-48f29dfcab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops sensors with nan values\n",
    "cols = (\"sensor_15\",\"sensor_50\",\"sensor_00\", \"sensor_06\", \"sensor_07\", \"sensor_08\", \"sensor_09\")\n",
    "df = df.drop(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0467c20a-7a63-48f7-a178-1c1e9aa50531",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fillna() got an unexpected keyword argument 'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_555/3277825713.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fill nan with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fillna() got an unexpected keyword argument 'method'"
     ]
    }
   ],
   "source": [
    "# fill nan with\n",
    "#df = df.fillna(method=\"pad\", limit=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c3c8408-b51a-4552-8fec-60a76f16756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops rows that contains nan values\n",
    "df = df.na.drop(\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef1722e6-0085-46cd-ae6d-19a7b8189506",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reset_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_555/1798029555.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reset index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \"\"\"\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1660\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[1;32m   1661\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reset_index'"
     ]
    }
   ],
   "source": [
    "# Reset index\n",
    "#df.reset_index(drop=True)\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52eaa72a-3bff-4949-9d94-249d55ce0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant Feature\n",
    "final_sensors = ['sensor_04', 'sensor_19', 'sensor_20', 'sensor_21', \n",
    "                 'sensor_38', 'sensor_39', 'sensor_40', 'sensor_41', \n",
    "                 'sensor_42']\n",
    "df = df.select(final_sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e6f0d5b1-aaca-475d-96fd-de70e862ec93",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "overwrite() missing 1 required positional argument: 'condition'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_555/2322654461.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark_catalog.default.pump_processed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iceberg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: overwrite() missing 1 required positional argument: 'condition'"
     ]
    }
   ],
   "source": [
    "df.writeTo(\"spark_catalog.default.pump_processed\").using(\"iceberg\").overwrite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d0ef95-1f93-43e7-a6ea-2d528778a687",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1512/4199070029.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mboto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3a://ps-uat2/user/dciciani/pump_sensor.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import boto\n",
    "data = pd.read_csv('s3a://ps-uat2/user/dciciani/pump_sensor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d00600-114a-44e1-b41d-d262b6fec22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3924ff8d-fa4a-4ec6-a4db-d36afbe0ac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Not running in a model replica, so using a local development\n",
      "version of the model metrics service. Please use the following\n",
      "CRN's to consume metrics:\n",
      "   model_crn: \"crn:cdp:ml:::workspace:dev/model\" (cdsw.dev_model_crn)\n",
      "   model_build_crn: \"crn:cdp:ml:::workspace:dev/model-build\" (cdsw.dev_model_build_crn)\n",
      "   model_deployment_crn: \"crn:cdp:ml:::workspace:dev/model-deployment\" (cdsw.dev_model_deployment_crn)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import cdsw, numpy, sklearn\n",
    "from cmlapi.utils import Cursor\n",
    "\n",
    "logged_model = '/home/cdsw/.experiments/n03k-3b0z-nbdp-wz8l/94k7-jivb-s3j1-g7r9/artifacts/model'\n",
    "\n",
    "\n",
    "@cdsw.model_metrics\n",
    "def predict(data):\n",
    "    \n",
    "    df = pd.DataFrame(data, index=[0])\n",
    "    df.columns = ['sensor_04', 'sensor_19', 'sensor_20', 'sensor_21', 'sensor_38', 'sensor_39', 'sensor_40', 'sensor_41', 'sensor_42']\n",
    "\n",
    "    #data = args.get('input')\n",
    "    # Load model as a PyFuncModel.\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    " \n",
    "    # Predict on a Pandas DataFrame.\n",
    "    pred = loaded_model.predict(df)\n",
    "    \n",
    "    cdsw.track_metric(\"prediction\", str(pred))\n",
    "    cdsw.track_metric(\"data\", data)\n",
    "   \n",
    "    return {'input_data': str(data), 'pred': str(pred[0])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc203213-74cc-4f0c-b4db-d60e09015d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': {'input_data': \"{'sensor_04': '4219', 'sensor_19': '31294', 'sensor_20': '421', 'sensor_21': '645', 'sensor_38': '664', 'sensor_39': '7654', 'sensor_40': '12', 'sensor_41': '1321', 'sensor_42': '3124'}\",\n",
       "  'pred': '0'},\n",
       " 'model_deployment_crn': 'crn:cdp:ml:::workspace:dev/model-deployment',\n",
       " 'uuid': '0e5235cc-a485-45b2-bf86-dcb76c6783ef'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \n",
    "  'sensor_04' : '4219',\n",
    "  'sensor_19' : '31294',\n",
    "  'sensor_20' : '421',\n",
    "  'sensor_21' : '645',\n",
    "  'sensor_38' : '664',\n",
    "  'sensor_39' : '7654',\n",
    "  'sensor_40' : '12',\n",
    "  'sensor_41' : '1321',\n",
    "  'sensor_42' : '3124',\n",
    "}\n",
    "\n",
    "predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dba9df1-54b2-4a78-b9f7-05d8b73373e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22868e0-c946-4c9f-b068-5ea7725b7e78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
